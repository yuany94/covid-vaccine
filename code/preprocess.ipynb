{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mounted-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assured-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.load('../data/pairs_full_12.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "poi2cbg = {}\n",
    "\n",
    "for cbg in tqdm(pairs):\n",
    "    for poi in pairs[cbg]:\n",
    "            if poi not in poi2cbg:\n",
    "                poi2cbg[poi] = {}\n",
    "            poi2cbg[poi][cbg] = pairs[cbg][poi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opened-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBG_data = pd.read_csv('../data/census_cbg_with_predicted_hesitancy_vaccincation.csv', error_bad_lines=False)\n",
    "prediction_vac = pd.read_csv('../data/vac_inferred_lvm.csv')\n",
    "CBG_data['FIPS Code'] = CBG_data['census_block_group'] // 10000000\n",
    "CBG_data = CBG_data.merge(prediction_vac, on='census_block_group')\n",
    "\n",
    "CBG_data['vac_rate_inferred_times_total_population'] = CBG_data['vac_rate_inferred'] * CBG_data['total_population']\n",
    "\n",
    "CBG_data_sum = CBG_data.groupby('FIPS Code')[['vac_rate_inferred_times_total_population', 'total_population']].sum()\n",
    "CBG_data_sum = CBG_data_sum.reset_index()\n",
    "CBG_data_sum['county_level_weighted_average'] = CBG_data_sum['vac_rate_inferred_times_total_population'] / CBG_data_sum['total_population']\n",
    "\n",
    "CBG_data = CBG_data.merge(CBG_data_sum[['FIPS Code', 'county_level_weighted_average']], on='FIPS Code')\n",
    "\n",
    "CBG_data['E_estimate_unsure'] = 1 - CBG_data['vac_rate_inferred'] / 100.0\n",
    "CBG_data['Estimated hesitant or unsure'] = 1 - CBG_data['county_level_weighted_average'] / 100.0\n",
    "\n",
    "CBG_data['E_estimate_unsure'] = np.minimum(CBG_data['E_estimate_unsure'], 1.0)\n",
    "CBG_data['E_estimate_unsure'] = np.maximum(CBG_data['E_estimate_unsure'], 0.0)\n",
    "\n",
    "CBG_data['Estimated hesitant or unsure'] = np.minimum(CBG_data['Estimated hesitant or unsure'], 1.0)\n",
    "CBG_data['Estimated hesitant or unsure'] = np.maximum(CBG_data['Estimated hesitant or unsure'], 0.0)\n",
    "\n",
    "vaccine = CBG_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accurate-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbg2population = {}\n",
    "\n",
    "for i, r in vaccine[['census_block_group', 'total_population']].iterrows():\n",
    "    cbg2population[r['census_block_group']] = r['total_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comparative-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois = set([poi for poi in poi2cbg if len(poi2cbg[poi]) >= 1])\n",
    "\n",
    "cbgs = [cbg for cbg in cbg2population if cbg2population[cbg] > 1]\n",
    "cbgs.sort()\n",
    "cbgs = set(cbgs)\n",
    "\n",
    "poi2idx = {}\n",
    "\n",
    "for poi in pois:\n",
    "    poi2idx[poi] = len(poi2idx)\n",
    "    \n",
    "cbg2idx = {}\n",
    "\n",
    "for cbg in cbgs:\n",
    "    cbg2idx[cbg] = len(cbg2idx)\n",
    "    \n",
    "# del pairs\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "vals = []\n",
    "\n",
    "for poi in poi2cbg:\n",
    "    if poi in pois:\n",
    "        for cbg in poi2cbg[poi]:\n",
    "            if cbg in cbgs:\n",
    "                rows.append(poi2idx[poi])\n",
    "                cols.append(cbg2idx[cbg])\n",
    "                vals.append(poi2cbg[poi][cbg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi2areas = np.load('../data/poi2area.npy', allow_pickle=True).item()\n",
    "poi2dwell_corrects_total = np.load('../data/poi2dwell_corrects_total.npy', allow_pickle=True).item()\n",
    "\n",
    "poi_areas = np.array([poi2areas[poi] for poi in poi2idx])\n",
    "poi_dwell_time_correction_factors = np.array([poi2dwell_corrects_total[poi] for poi in poi2idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subjective-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "bipartite = csr_matrix((vals, (rows, cols)), shape=(len(poi2idx), len(cbg2idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-cedar",
   "metadata": {},
   "source": [
    "# Remember to gc some memory :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "transparent-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_param = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "shared-warehouse",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_param['all_states'] = {}\n",
    "dict_param['all_hours'] = {}\n",
    "dict_param['cbg_idx_groups_to_track'] = {}\n",
    "dict_param['cbg_day_prop_out'] = {}\n",
    "dict_param['intervention_cost'] = {}\n",
    "dict_param['poi_subcategory_types'] = {}\n",
    "dict_param['cbgs_idxs'] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "intensive-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_scores_array = np.array(bipartite_normed_product.sum(axis=1))[:, 0]\n",
    "centrality_scores = {ii: centrality_scores_array[ii] for ii in range(len(centrality_scores_array))}\n",
    "centrality_scores = list(reversed(sorted(centrality_scores.items(), key=lambda x: x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "persistent-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dict = {}\n",
    "\n",
    "dict_param['poi_cbg_visits_list'] = [bipartite]\n",
    "dict_param['poi_time_counts'] = np.array([np.ones(len(poi2idx))]).T\n",
    "\n",
    "poi2areas = np.load('../data/poi2area.npy', allow_pickle=True).item()\n",
    "dict_param['poi_areas'] = np.array([poi2areas[poi] for poi in poi2idx])\n",
    "\n",
    "poi2dwell_corrects_total = np.load('../data/poi2dwell_corrects_total_12.npy', allow_pickle=True).item()\n",
    "\n",
    "dict_param['poi_dwell_time_correction_factors'] = np.array([poi2dwell_corrects_total[poi] \n",
    "                            if poi in poi2dwell_corrects_total else 0.0\n",
    "                            for poi in poi2idx])\n",
    "cbg2population = {}\n",
    "\n",
    "for i, r in vaccine[['census_block_group', 'total_population']].iterrows():\n",
    "    cbg2population[r['census_block_group']] = r['total_population']\n",
    "\n",
    "dict_param['all_unique_cbgs'] = list(cbgs)\n",
    "dict_param['cbg_sizes'] = np.array([cbg2population[int(cbg)] for cbg in dict_param['all_unique_cbgs']])\n",
    "\n",
    "\n",
    "dict_param['poi_cbg_proportions'] = [{1: 0.9}] * len(poi2idx)\n",
    "\n",
    "\n",
    "unvax = np.ones(bipartite.shape[1]) * np.median(vaccine['E_estimate_unsure'])\n",
    "\n",
    "for i, r in vaccine.iterrows():\n",
    "    cbg = r['census_block_group']\n",
    "    if cbg in cbg2idx:\n",
    "        unvax[cbg2idx[cbg]] = r['E_estimate_unsure']\n",
    "\n",
    "\n",
    "dict_param['unvax'] = copy.deepcopy(unvax)\n",
    "\n",
    "dict_param['cbgs_to_idxs']= {}\n",
    "\n",
    "for cbg in dict_param['all_unique_cbgs']:\n",
    "    dict_param['cbgs_to_idxs'][cbg] = len(dict_param['cbgs_to_idxs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "czech-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/dict_param_all_12.npy', dict_param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-transmission",
   "metadata": {},
   "source": [
    "# clear the memory and delete some data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois = set([poi for poi in poi2cbg if len(poi2cbg[poi]) >= 1])\n",
    "\n",
    "cbgs = [cbg for cbg in cbg2population if cbg2population[cbg] > 1]\n",
    "cbgs.sort()\n",
    "cbgs = set(cbgs)\n",
    "\n",
    "poi2idx = {}\n",
    "\n",
    "for poi in pois:\n",
    "    poi2idx[poi] = len(poi2idx)\n",
    "    \n",
    "cbg2idx = {}\n",
    "\n",
    "for cbg in cbgs:\n",
    "    cbg2idx[cbg] = len(cbg2idx)\n",
    "    \n",
    "# del pairs\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "vals = []\n",
    "\n",
    "for poi in poi2cbg:\n",
    "    if poi in pois and poi in poi2dwell_corrects_total and poi in poi2areas:\n",
    "        for cbg in poi2cbg[poi]:\n",
    "            if cbg in cbgs:\n",
    "                rows.append(poi2idx[poi])\n",
    "                cols.append(cbg2idx[cbg])\n",
    "                vals.append(poi2cbg[poi][cbg] * np.sqrt(poi2dwell_corrects_total[poi] / poi2areas[poi]))\n",
    "    \n",
    "print(vals)\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "bipartite = csr_matrix((vals, (rows, cols)), shape=(len(poi2idx), len(cbg2idx)))\n",
    "# np.save('bipartite_weight_12.npy', bipartite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "musical-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "right = (bipartite @ np.ones(214697))\n",
    "bipartite_normed_product = bipartite.T @ right\n",
    "np.save('../results/centrality_files/bipartite_normed_product_all_12.npy', bipartite_normed_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-american",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
